# CI/CD Pipeline for Wan2.2 UI Variant with Local Testing Framework
# This GitHub Actions workflow provides comprehensive testing and deployment

name: Wan2.2 UI Variant CI/CD

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    # Run nightly tests at 2 AM UTC
    - cron: "0 2 * * *"

env:
  PYTHON_VERSION: "3.9"
  CUDA_VERSION: "11.8"

jobs:
  # Environment validation and setup
  validate-environment:
    runs-on: ubuntu-latest
    outputs:
      python-version: ${{ steps.setup.outputs.python-version }}
      cuda-available: ${{ steps.cuda-check.outputs.available }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        id: setup
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -e .

      - name: Check CUDA availability
        id: cuda-check
        run: |
          python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
          echo "available=$(python -c 'import torch; print(torch.cuda.is_available())')" >> $GITHUB_OUTPUT

      - name: Run environment validation
        run: |
          python -m local_testing_framework validate-env --report

      - name: Upload environment report
        uses: actions/upload-artifact@v4
        with:
          name: environment-validation-report
          path: reports/environment_validation.json

  # Unit and integration tests
  test-framework:
    runs-on: ubuntu-latest
    needs: validate-environment
    strategy:
      matrix:
        test-type: [unit, integration, performance]

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ needs.validate-environment.outputs.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
          pip install -e .

      - name: Run unit tests
        if: matrix.test-type == 'unit'
        run: |
          python -m pytest local_testing_framework/tests/unit/ -v --cov=local_testing_framework --cov-report=xml

      - name: Run integration tests
        if: matrix.test-type == 'integration'
        run: |
          python -m local_testing_framework test-integration --full --report-format json

      - name: Run performance tests
        if: matrix.test-type == 'performance'
        run: |
          python -m local_testing_framework test-performance --benchmark --report-format json

      - name: Upload test results
        uses: actions/upload-artifact@v4
        with:
          name: reports-tests-${{ matrix.test-type }}
          path: reports/

  # Security and code quality checks
  security-checks:
    runs-on: ubuntu-latest
    needs: validate-environment

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ needs.validate-environment.outputs.python-version }}

      - name: Install security tools
        run: |
          python -m pip install --upgrade pip
          pip install bandit safety

      - name: Run Bandit security scan
        run: |
          bandit -r local_testing_framework/ -f json -o bandit-report.json

      - name: Run Safety check
        run: |
          safety check --json --output safety-report.json

      - name: Upload security reports
        uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: |
            bandit-report.json
            safety-report.json

  # Build and test Docker image
  build-docker:
    runs-on: ubuntu-latest
    needs: [validate-environment, test-framework]

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Build Docker image
        uses: docker/build-push-action@v4
        with:
          context: .
          file: local_testing_framework/examples/deployment/docker/Dockerfile
          tags: wan22/ui-variant:${{ github.sha }}
          load: true
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Test Docker image
        run: |
          docker run --rm wan22/ui-variant:${{ github.sha }} python -m local_testing_framework validate-env --quick

      - name: Save Docker image
        run: |
          docker save wan22/ui-variant:${{ github.sha }} | gzip > wan22-ui-variant.tar.gz

      - name: Upload Docker image artifact
        uses: actions/upload-artifact@v4
        with:
          name: docker-image
          path: wan22-ui-variant.tar.gz

  # Deployment to staging
  deploy-staging:
    runs-on: ubuntu-latest
    needs: [test-framework, security-checks, build-docker]
    if: github.ref == 'refs/heads/develop'
    environment: staging

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Download Docker image
        uses: actions/download-artifact@v4
        with:
          name: docker-image

      - name: Load Docker image
        run: |
          docker load < wan22-ui-variant.tar.gz

      - name: Deploy to staging
        run: |
          # Configure staging environment
          cp local_testing_framework/examples/configurations/staging_config.json config.json

          # Run deployment script
          bash local_testing_framework/examples/deployment/scripts/deploy.sh docker staging

      - name: Run post-deployment validation
        run: |
          python -m local_testing_framework run-all --report-format json --output reports/staging-deployment

      - name: Upload deployment report
        uses: actions/upload-artifact@v4
        with:
          name: staging-deployment-report
          path: reports/staging-deployment/

  # Deployment to production
  deploy-production:
    runs-on: ubuntu-latest
    needs: [deploy-staging]
    if: github.ref == 'refs/heads/main'
    environment: production

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Download Docker image
        uses: actions/download-artifact@v4
        with:
          name: docker-image

      - name: Load Docker image
        run: |
          docker load < wan22-ui-variant.tar.gz

      - name: Run pre-deployment validation
        run: |
          python local_testing_framework/examples/workflows/pre_deployment_validation.py --environment production --strict

      - name: Deploy to production
        run: |
          # Configure production environment
          cp local_testing_framework/examples/configurations/production_config.json config.json

          # Run deployment script
          bash local_testing_framework/examples/deployment/scripts/deploy.sh docker production

      - name: Run post-deployment validation
        run: |
          python -m local_testing_framework run-all --report-format json --output reports/production-deployment

      - name: Upload deployment report
        uses: actions/upload-artifact@v4
        with:
          name: production-deployment-report
          path: reports/production-deployment/

  # Continuous monitoring setup
  setup-monitoring:
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: github.ref == 'refs/heads/main'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Start continuous monitoring
        run: |
          # Start monitoring in background
          nohup python local_testing_framework/examples/workflows/continuous_monitoring_workflow.py \
            --duration 86400 --alerts --profile prod > monitoring.log 2>&1 &

          echo "Continuous monitoring started"

  # Nightly comprehensive tests
  nightly-tests:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -e .

      - name: Run comprehensive test suite
        run: |
          python -m local_testing_framework run-all --report-format html --output reports/nightly

      - name: Upload nightly test report
        uses: actions/upload-artifact@v4
        with:
          name: nightly-test-report
          path: reports/nightly/

      - name: Send notification on failure
        if: failure()
        uses: actions/github-script@v6
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'Nightly Tests Failed',
              body: 'The nightly comprehensive test suite has failed. Please check the logs and reports.',
              labels: ['bug', 'nightly-tests']
            })

  # Performance regression detection
  performance-regression:
    runs-on: ubuntu-latest
    needs: test-framework
    if: github.event_name == 'pull_request'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -e .

      - name: Run performance benchmarks
        run: |
          python -m local_testing_framework test-performance --benchmark --report-format json

      - name: Compare with baseline
        run: |
          # Download baseline performance data
          # Compare current results with baseline
          # Report any significant regressions
          echo "Performance regression check completed"

  # Documentation generation
  generate-docs:
    runs-on: ubuntu-latest
    needs: [test-framework]
    if: github.ref == 'refs/heads/main'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install documentation dependencies
        run: |
          python -m pip install --upgrade pip
          pip install sphinx sphinx-rtd-theme

      - name: Generate API documentation
        run: |
          sphinx-build -b html docs/ docs/_build/html

      - name: Deploy documentation
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: docs/_build/html

  # Cleanup and notifications
  cleanup:
    runs-on: ubuntu-latest
    needs: [deploy-production, setup-monitoring]
    if: always()

    steps:
      - name: Clean up artifacts
        run: |
          echo "Cleaning up temporary artifacts and resources"

      - name: Send success notification
        if: success()
        run: |
          echo "Pipeline completed successfully"

      - name: Send failure notification
        if: failure()
        run: |
          echo "Pipeline failed - check logs for details"
